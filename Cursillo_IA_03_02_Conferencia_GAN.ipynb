{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "    <img src=\"../imagenes/Foto Alvaro Montenegro.png\" width=\"40\" height=\"40\" align=\"right\" /> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:#4361EE\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Simposio Internacional de Estadística 2024</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"><center>Minicurso de Inteligencia Artificial Moderna - Sesión III<center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"><center>Modelos Generativos - GANs<center></span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/8/82/%D0%9D%D0%B0%D0%B9%D0%BA%D1%80%D0%B0%D1%89%D1%96_%D0%BC%D0%B8%D1%82%D1%96_%D0%B6%D0%B8%D1%82%D1%82%D1%8F.jpg width=\"400\" height=\"400\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Rhododendron flowers in the Carpathian Mountains</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: <a href=\"https://commons.wikimedia.org/wiki/File:%D0%9D%D0%B0%D0%B9%D0%BA%D1%80%D0%B0%D1%89%D1%96_%D0%BC%D0%B8%D1%82%D1%96_%D0%B6%D0%B8%D1%82%D1%82%D1%8F.jpg\">Misha Reme</a>, <a href=\"https://creativecommons.org/licenses/by-sa/4.0\">CC BY-SA 4.0</a>, via Wikimedia Commons\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# <span style=\"color:#4361EE\">Profesor</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4361EE\">Alvaro  Mauricio Montenegro Díaz, Ph.D.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ScgciUekeLx"
   },
   "source": [
    "## <span style=\"color:blue\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ScgciUekeLx"
   },
   "source": [
    "1. [Rowel Atiesa, Advanced Deep Learning with Tensorflow 2 and Keras, second ed., Pack, 2020](https://www.oreilly.com/library/view/advanced-deep-learning/9781838821654/)\n",
    "1. [Ejemplos de Keras](https://keras.io/examples/generative/dcgan_overriding_train_step/)\n",
    "1. [Tutoriales-Tensorflow](https://www.tensorflow.org/tutorials/generative/dcgan)\n",
    "1. [Soumith, How to Train a GAN? Tips and tricks to make GANs workHow to Train a GAN? Tips and tricks to make GANs work](https://github.com/soumith/ganhacks/blob/master/README.mdhttps://github.com/soumith/ganhacks/blob/master/README.md), in Github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOKqkYEZkeL0"
   },
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Preliminares](#Preliminares)\n",
    "* [Componentes de una GAN](#Componentes-de-una-GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgu76LPXkeL1",
    "tags": []
   },
   "source": [
    "# <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Las redes generativas adversarias (GAN) son una de las más interesantes ideas de la inteligencia artificial hoy en día. Dos modelos son entrenados simultáneamente por un proceso adversario. \n",
    "\n",
    "Un `generador` ( \"el artista\") aprende a crear imágenes que parecen reales, mientras que un `discriminador` ( \"el crítico de arte\") aprende a decidir si las imágenes son reales o no.\n",
    "\n",
    "El propósito del entrenamiento es que el generador aprenda a crear imágenes de tal calidad que el discriminador no logre diferenciar si son reales o `falsificaciones`. \n",
    "\n",
    "En  paralelo, el discriminador se vuelve el mejor en detectar falsificaciones. Las GAN fueron propuestas por [Ian Goodfellow](https://en.wikipedia.org/wiki/Ian_Goodfellow), estudiante de doctorado de [Yoshua BengioYoshua Bengio](https://en.wikipedia.org/wiki/Yoshua_Bengio).\n",
    "\n",
    "La siguiente imagen tomada de los tutoriales de Google, ilustra los principales elementos que se requieren para construir una GAN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/gan1.png\" width=\"600\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Generador y discriminador de una GAN </p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [Tutoriales-Tensorflow](https://www.tensorflow.org/tutorials/generative/dcgan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante el entrenamiento, el generador se vuelve progresivamente cada vez más capaz de crear imágenes que parecen reales, mientras que el discriminador se convierte en el mejor para distinguirlas. Se alcanza una situación  de equilibrio cuando el discriminador ya no puede distinguir imágenes reales de los falsos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/gan2.png\" width=\"500\" height=\"400\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">GAN en acción </p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente: [Tutoriales-Tensorflow](https://www.tensorflow.org/tutorials/generative/dcgan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta lección también veremos como generar imágenes de caras usando una red generativa adversaria convolucional (DCGAN), lacual es na evolución de las GAN's clásicas. \n",
    "\n",
    "Utilizaremos un subconjunto del conjunto de datos de imágenes de celebridades [CelebFaces Attributes (CelebA) Dataset](https://www.kaggle.com/jessicali9530/celeba-dataset) disponible en Kaggle. CelebA tiene más de 200k imágenes de celebridades con 40 anotaciones de tipo binario. Nos hemos basado en el código de F. Chollet, el creador de Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Concepto básicos de las GANs</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Componentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las GANs consisten en dos redes neuronales que compiten entre sí en un juego de suma cero. Estas redes son el Generador y el Discriminador.\n",
    "\n",
    "1. `Generador (G)`: Intenta crear datos falsos que parezcan reales.\n",
    "2. `Discriminador (D)`: Intenta distinguir entre los datos reales y los generados por el Generador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Generador</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Generador toma como entrada un vector de ruido, generalmente una distribución aleatoria, y lo transforma en datos que intentan parecerse a los datos reales. La idea es que el Generador aprenda a mapear el espacio de ruido a la distribución de datos reales.\n",
    "\n",
    "1. `Entrada`: Vector de ruido $z$.\n",
    "2. `Salida`: Datos sintéticos generados (por ejemplo, imágenes).\n",
    "\n",
    "\n",
    "\n",
    "El siguiente fragmento muestra cómo se podría construir una red generadora clásica con Tensorflow. El ejemplo se podría utilizar para generar imagenes de Mnist o Fashion Mnist. Observe que se espera a la entrada un vector ($z$) de tamaño 100. A la salida esperariamos una imagen de tamaño $28 \\times 28$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">803,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m25,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │       \u001b[38;5;34m525,312\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │       \u001b[38;5;34m803,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,486,352</span> (5.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,486,352\u001b[0m (5.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,486,352</span> (5.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,486,352\u001b[0m (5.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ejemplo de generador\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Reshape, Flatten, LeakyReLU, Dropout\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=100))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(784, activation='tanh'))\n",
    "    model.add(Reshape((28, 28, 1)))\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#4CC9F0\">Prueba del generador aún no  entrenado</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos el generador, todavía no entrenado, para crear una imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x313bf3020>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Ejercicio</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigue la definición de la activación *LeakyReLU*. y haga un gráfico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consigne su respuesta aquí**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Posible solución**.\n",
    "La función activación `LeakyReLU` n es definida como sigue:\n",
    "\n",
    "$$\n",
    "\\text{LeakyReLU}(x) = \\begin{cases} x &\\text{ si } x>0\\\\\n",
    "\\alpha x, \\hspace{3mm}0 <\\alpha < 1 &\\text{ si } x\\le 0 \\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Discriminador</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Discriminador toma como entrada tanto datos reales como datos generados por el Generador y trata de clasificar cada uno como real o falso. En otras palabras, el Discriminador es un clasificador binario.\n",
    "\n",
    "1. `Entrada`: Datos reales o datos generados.\n",
    "2. `Salida`: Probabilidad de que los datos sean reales.\n",
    "\n",
    "El siguiente fragmento muestra cómo se podría construir una red generadora clásica con Tensorflow. El ejemplo se podría utilizar para generar imagenes de Mnist o Fashion Mnist. Observe que se espera a la entrada un vector ($z$) de tamaño 100. A la salida esperariamos una imagen de tamaño $28 \\times 28$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m401,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_8 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_9 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">533,505</span> (2.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m533,505\u001b[0m (2.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">533,505</span> (2.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m533,505\u001b[0m (2.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ejemplo de discriminador\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Reshape, Flatten, LeakyReLU, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Prueba del discriminador no entrenado aún</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el discriminador, todavía no entrenado, para clasificar las imágenes generadas como reales o falsas. El modelo se entrenará para generar valores positivos para imágenes reales y valores negativos para imágenes falsas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.5858497]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Funcionamiento</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Inicialización**: Ambas redes, Generador y Discriminador, se inicializan con pesos aleatorios.\n",
    "2. **Entrenamiento del Discriminador**:\n",
    "    * Se presentan al Discriminador muestras reales del conjunto de datos etiquetadas como reales.\n",
    "    * Se presentan al Discriminador muestras generadas por el Generador etiquetadas como falsas.\n",
    "    * El Discriminador se entrena para maximizar su precisión en distinguir entre reales y falsos.\n",
    "3. **Entrenamiento del Generador**:\n",
    "   * Se genera un lote de datos falsos a partir del Generador.\n",
    "   * Se pasa este lote al Discriminador pero, en lugar de actualizar los pesos del Discriminador, se actualizan los pesos del Generador.\n",
    "   * El Generador se entrena para minimizar la capacidad del Discriminador para distinguir entre reales y falsos.\n",
    "4. **Ciclo de Entrenamiento**:\n",
    "     * Se alternan los pasos de entrenamiento del Generador y del Discriminador hasta que se alcanza un equilibrio donde el Generador produce datos que el Discriminador no puede distinguir de los datos reales con alta precisión.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Pérdida (Loss)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las GANs usan una función de pérdida que refleja el objetivo de ambos modelos:\n",
    "\n",
    "* **Pérdida del Discriminador**: $\\log(𝐷(𝑥)) + \\log(1−𝐷(𝐺(𝑧)))$\n",
    "    + $D(x)$ es la probabilidad de que la entrada $x$ sea real.\n",
    "     + $𝐺(𝑧)$ es la salida del Generador cuando la entrada es $z$ (vector de ruido).\n",
    "    + El Discriminador trata de maximizar esta función de pérdida.\n",
    "* **Pérdida del Generador**: $\\log(1−D(G(z)))$\n",
    "    + El Generador trata de minimizar esta función de pérdida.\n",
    "    + Alternativamente, puede maximizar $\\log(D(G(z)))$, lo que a menudo lleva a una convergencia más rápida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Beneficios y Desafíos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Beneficios**\n",
    "    + `Generación de Datos Realistas`: Las GANs pueden generar datos increíblemente realistas, lo cual es útil en aplicaciones como la creación de imágenes, videos y música.\n",
    "    + `Aprendizaje Sin Supervisión`: Las GANs no requieren etiquetas para el entrenamiento, lo cual es beneficioso cuando no se dispone de grandes conjuntos de datos etiquetados.\n",
    "2. **Desafíos**\n",
    "    + Entrenamiento Inestable: Encontrar el equilibrio entre el Generador y el Discriminador puede ser difícil, y el entrenamiento puede ser inestable.\n",
    "    + `Modo Colapso`: El Generador puede llegar a producir una gama limitada de resultados (colapso del modo), ignorando otras partes de la distribución de datos reales.\n",
    "    + `Recursos Computacionales`: Las GANs pueden requerir grandes recursos computacionales para entrenarse adecuadamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Variantes de GANs</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las Redes Generativas Adversarias (GANs) han evolucionado significativamente desde su introducción en 2014. A lo largo de los años, se han propuesto varias variantes de GANs para abordar diferentes desafíos y mejorar la estabilidad, calidad y eficiencia del entrenamiento. A continuación, se presentan algunas de las variantes más importantes de GANs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Deep Convolutional GANs (DCGANs)</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descripción**: Introducidas por Alec Radford, Luke Metz y Soumith Chintala en 2015, las DCGANs utilizan redes neuronales convolucionales profundas en lugar de capas densas, lo que mejora significativamente la calidad de las imágenes generadas.\n",
    "\n",
    "**Características Clave**:\n",
    "+ Uso de convoluciones en lugar de capas densas.\n",
    "+ Capas de normalización por lotes (Batch Normalization) para estabilizar el entrenamiento.\n",
    "+ Funciones de activación LeakyReLU en el Discriminador y ReLU en el Generador.\n",
    "\n",
    "El siguiente fragmento de código presenta una implementación básica de una DCGAN en Tensorflow, para generar por ejemplo imágenes Mnist o FashionMnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_dcgan(z_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7*7*256, input_dim=z_dim))\n",
    "    model.add(Reshape((7, 7, 256)))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=5, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))\n",
    "    return model\n",
    "\n",
    "def build_discriminator_dcgan():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28, 28, 1), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(128, kernel_size=5, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Conditional GANs (cGANs)</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descripción**: Propuestas por Mehdi Mirza y Simon Osindero en 2014, las cGANs condicionan tanto al Generador como al Discriminador con información adicional (por ejemplo, etiquetas de clase).\n",
    "\n",
    "**Características Clave**:\n",
    "+ Condicionamiento de entrada en el Generador y el Discriminador.\n",
    "+ Mejor control sobre el tipo de datos generados.\n",
    "\n",
    "El siguiente fragmento de código presenta una implementación básica de una CGAN en Tensorflow, para generar por ejemplo imágenes Mnist o FashionMnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_cgan(z_dim, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=z_dim + num_classes))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(784, activation='tanh'))\n",
    "    model.add(Reshape((28, 28, 1)))\n",
    "    return model\n",
    "\n",
    "def build_discriminator_cgan(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28, 1 + num_classes)))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Wasserstein GANs (WGANs)</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descripción**: Introducidas por Martin Arjovsky y sus colegas en 2017, las WGANs utilizan la distancia de Wasserstein como métrica de pérdida, mejorando la estabilidad del entrenamiento y proporcionando una mejor convergencia.\n",
    "\n",
    "**Características Clave**:\n",
    "\n",
    "+ Uso de la distancia de Wasserstein en lugar de la pérdida de entropía cruzada.\n",
    "+ Clipping de pesos para mantener la red dentro de un rango específico.\n",
    "\n",
    "El siguiente fragmento de código presenta una implementación básica de una Wasserstein en Tensorflow, para generar por ejemplo imágenes Mnist o FashionMnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "def build_discriminator_wgan():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=784))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "def build_generator_wgan(z_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=z_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(784, activation='tanh'))\n",
    "    model.add(Reshape((28, 28, 1)))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Least Squares GANs (LSGANs)</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descripción**: Propuestas por Xudong Mao y sus colegas en 2016, las LSGANs utilizan una función de pérdida de mínimos cuadrados en lugar de la pérdida de entropía cruzada, lo que puede resultar en gradientes más estables y de mejor calidad.\n",
    "\n",
    "**Características Clave**:\n",
    "\n",
    "+ Uso de la pérdida de mínimos cuadrados en lugar de la entropía cruzada.\n",
    "+ Mejora en la calidad y estabilidad de las imágenes generadas.\n",
    "\n",
    "El siguiente fragmento de código presenta una implementación básica de una LSGAN en Tensorflow, para generar por ejemplo imágenes Mnist o FashionMnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_lsgan(z_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=z_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(784, activation='tanh'))\n",
    "    model.add(Reshape((28, 28, 1)))\n",
    "    return model\n",
    "\n",
    "def build_discriminator_lsgan():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28, 1)))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">CycleGAN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descripción**: Propuestas por Jun-Yan Zhu y sus colegas en 2017, las CycleGANs permiten el mapeo de imágenes de un dominio a otro sin la necesidad de pares de entrenamiento (por ejemplo, transformar imágenes de caballos en cebras y viceversa).\n",
    "\n",
    "**Características Clave**:\n",
    "\n",
    "+ Transformación de imágenes entre dos dominios sin necesidad de pares de datos.\n",
    "+ Uso de pérdidas de ciclo-consistencia para asegurar que las transformaciones sean reversibles.\n",
    "\n",
    "El siguiente fragmento de código presenta una implementación básica de una CycleGAN en Tensorflow, para generar por ejemplo imágenes Mnist o FashionMnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator_cyclegan():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=7, padding='same', input_shape=(128, 128, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Varias capas residuales aquí...\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(3, kernel_size=7, padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    return model\n",
    "\n",
    "def build_discriminator_cyclegan():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=(128, 128, 3)))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(256, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(512, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Entrenamiento de las GANs</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/GAN_trainig.png\" width=\"600\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Esquema de entrenamiento de una GAN </p>\n",
    "</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El entrenamiento de las Redes Generativas Adversarias (GANs) es un proceso iterativo y competitivo que involucra dos redes neuronales: el Generador y el Discriminador. Aquí desglosamos los pasos clave y las técnicas para entrenar GANs de manera efectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Proceso de Entrenamiento</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El entrenamiento de una GAN implica alternar entre el entrenamiento del Discriminador y el Generador. El objetivo es encontrar un equilibrio donde el Generador produzca datos tan realistas que el Discriminador no pueda diferenciarlos de los datos reales con alta precisión.\n",
    "\n",
    "**Pasos Detallados**:\n",
    "1. **Inicialización**:\n",
    "    1. Inicializa los pesos del Generador y el Discriminador.\n",
    "    2. Establece los hiperparámetros, como la tasa de aprendizaje, el tamaño del lote, y el número de épocas.\n",
    "\n",
    "2. **Entrenamiento del Discriminador**:\n",
    "\n",
    "    1. Toma un lote de datos reales del conjunto de datos y genera un lote de datos falsos utilizando el Generador.\n",
    "    2. Calcula la pérdida del Discriminador en los datos reales y falsos.\n",
    "    3. Actualiza los pesos del Discriminador para maximizar su capacidad de distinguir entre datos reales y falsos.\n",
    "\n",
    "3. **Entrenamiento del Generador**:\n",
    "\n",
    "+ Genera un lote de datos falsos a partir de un vector de ruido.\n",
    "+ Pasa estos datos falsos al Discriminador, pero no actualiza los pesos del Discriminador.\n",
    "+ Calcula la pérdida del Generador basada en la capacidad del Discriminador para clasificar los datos falsos como reales.\n",
    "+ Actualiza los pesos del Generador para minimizar la capacidad del Discriminador de diferenciar entre datos reales y falsos.\n",
    "\n",
    "4. **Repetición**:\n",
    "\n",
    "+ Repite los pasos anteriores durante varias épocas hasta que la GAN alcance un equilibrio y el Generador produzca datos realistas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Funciones de Pérdida</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones de pérdida juegan un papel crucial en el entrenamiento de las GANs. Las funciones de pérdida comunes incluyen: \n",
    "\n",
    "**Pérdida del Discriminador**\n",
    "+  $L_D = −\\mathbb{E}[\\log D(x)]−\\mathbb{E}[\\log(1−D(G(z)))]$\n",
    "**Pérdida del Discriminador**\n",
    "+ $L_G =−E[logD(G(z))]$\n",
    "\n",
    " \n",
    "En WGANs, se usa la distancia de Wasserstein:\n",
    "\n",
    "c:\n",
    "$L_D =  =E[D(x)]−E[D(G(z))]$\n",
    "\n",
    " \n",
    "+ **Pérdida del Generador**\n",
    "+ $L_D  =−E[D(G(z))]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Técnicas de Mejora del Entrenamiento</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalización de Lotes (Batch Normalization)**\n",
    "\n",
    "La normalización de lotes se usa para estabilizar el entrenamiento y acelerar la convergencia. Se aplica a las capas del Generador y el Discriminador.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# Ejemplo en una capa del Generador\n",
    "model.add(Dense(256, input_dim=z_dim))\n",
    "model.add(BatchNormalization(momentum=0.8))\n",
    "model.add(LeakyReLU(alpha=0.2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clipping de Pesos**\n",
    "\n",
    "En WGANs, se recortan los pesos del Discriminador para mantener la estabilidad del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in discriminator.layers:\n",
    "    weights = layer.get_weights()\n",
    "    weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "    layer.set_weights(weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uso de Optimizadores**\n",
    "\n",
    "Adam es un optimizador comúnmente utilizado por su capacidad para adaptarse a diferentes tasas de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "generator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenamiento Alternado**\n",
    "\n",
    "Es crucial alternar entre el entrenamiento del Generador y el Discriminador para asegurar que ambos mejoren simultáneamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "batch_size = 64\n",
    "sample_interval = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Entrenamiento del Discriminador\n",
    "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "    real_imgs = X_train[idx]\n",
    "    noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    d_loss_real = discriminator.train_on_batch(real_imgs, np.ones((batch_size, 1)))\n",
    "    d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((batch_size, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Entrenamiento del Generador\n",
    "    noise = np.random.normal(0, 1, (batch_size, z_dim))\n",
    "    g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "    # Progreso\n",
    "    if epoch % sample_interval == 0:\n",
    "        print(f\"{epoch} [D loss: {d_loss[0]}, acc.: {100 * d_loss[1]}%] [G loss: {g_loss}]\")\n",
    "        save_images(epoch, generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluación del Desempeño**\n",
    "\n",
    "Evaluar el desempeño de las GANs puede ser complicado debido a la naturaleza generativa de las redes. Algunas métricas y técnicas comunes incluyen:\n",
    "\n",
    "+ `Frechet Inception Distance (FID)`: Mide la distancia entre las distribuciones de características extraídas de las imágenes reales y generadas usando una red de clasificación preentrenada (por ejemplo, Inception Network).\n",
    "+ `Inception Score (IS)`: Evalúa la calidad y diversidad de las imágenes generadas basándose en las predicciones de una red de clasificación preentrenada.\n",
    "  \n",
    "**Generación y Visualización de Imágenes**\n",
    "\n",
    "Guardar y visualizar imágenes generadas durante el entrenamiento es útil para monitorear el progreso del Generador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(epoch, generator, z_dim=100, examples=16, dim=(4, 4), figsize=(10, 10)):\n",
    "    noise = np.random.normal(0, 1, (examples, z_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(dim[0], dim[1], figsize=figsize)\n",
    "    cnt = 0\n",
    "    for i in range(dim[0]):\n",
    "        for j in range(dim[1]):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefinir el paso de entrenamiento es el principal ingrediente de las GAN. Se siguen los siguientes pasos:\n",
    "\n",
    "\n",
    "1.  A la entrada la función recibe, como siempre ocurre, un lote (batch) de imágenes de entrenamiento reales.\n",
    "1. Genera un lote (batch) de puntos aleatorios del mismo tamaño del lote de entrada a la función.  Supongamos que el tamaño del espacio latente de representación es de tamaño $n$. Entonces genera un lotes de observaciones usando la distribución normal multivariada estándar $\\mathfrak{N}_n(\\boldsymbol{0},\\boldsymbol{I})$.\n",
    "1. Con el lote de aleatorios usa el generador para generar un lote de imágenes falsas.\n",
    "1. Combina (concatena) los dos lotes: imágenes falsas generadas e imágenes reales.\n",
    "1.  Etiqueta todas las imágenes, discriminado las reales de las falsas.\n",
    "1. Agrega ruido aleatorio a las etiquetas: ¡truco importante!. Esto hará que el discriminador reciba de vez en cuando información totalmente cambiada. En particular algunas etiquetas falsas se verán como verdaderas y viceversa. Se pretende con esto engañar al discriminador. Revise la siguiente imagen.\n",
    "1. Entrena al discriminador. Se pasan las imágenes combinadas al discriminador para que prediga las respectivas etiquetas. Con estas predicciones se calcula la pérdida del discriminador y se actualizan sus pesos (parámetros). El generador permanece ajeno a este proceso.\n",
    "1. Genera un nuevo lote de aleatorios como se hizo arriba.\n",
    "1. Etiqueta todas esta imágenes  diciendo que todas son \"imágenes reales\"\n",
    "1. Entrena el generador (tenga en cuenta que **no** debemos actualizar los pesos del discriminador en este paso). Los aleatorios son pasados por el generador y entregados al discriminador, el cual hace la predicción. La función de pérdida del generador hace el mismo trabajo que hace la función de pérdida del discriminador (*entropía cruzada*), pero aquí las etiquetas de las imágenes falsas se colocaron como verdaderas, obligando al generador a hacer mejor el trabajo de falsificación.\n",
    "1. Eso es todo. Al final se re-calculan las métricas y se retornan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../Imagenes/gan_training2.png\" width=\"400\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Entradas al discriminador </p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "Fuente [Soumith, How to Train a GAN? Tips and tricks to make GANs workHow to Train a GAN? Tips and tricks to make GANs work](https://github.com/soumith/ganhacks/blob/master/README.mdhttps://github.com/soumith/ganhacks/blob/master/README.md), in Github."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
